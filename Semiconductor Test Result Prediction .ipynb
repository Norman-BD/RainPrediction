{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('uci-secom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 592 entries, Time to Pass/Fail\n",
      "dtypes: float64(590), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(df): \n",
    "    df = df.copy()\n",
    "    \n",
    "    #drop the time columns from axis 1 \n",
    "    df = df.drop('Time', axis=1 )\n",
    "    \n",
    "    # drop the isna columns \n",
    "    missing_value_columns = df.columns[df.isna().mean()>= 0.25] \n",
    "    df = df.drop(missing_value_columns ,axis=1 )\n",
    "    \n",
    "    # fill the missing value in here \n",
    "    for column in df.columns:\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "            \n",
    "    # replace -1 and 1 to pass and fail in here \n",
    "    df['Pass/Fail'] = df['Pass/Fail'].replace({-1:'Pass', 1:'Fail'})\n",
    "    \n",
    "    # remove the single variable in here \n",
    "    single_value_columns = [\n",
    "            '5','13','42','49','52','69','97','141','149','178','179','186','189','190',\n",
    "'191','192','193','194','226','229','230','231','232','233','234','235','236',\n",
    "'237','240','241','242','243','256','257','258','259','260','261','262','263',\n",
    "'264','265','266','276','284','313','314','315','322','325','326','327','328',\n",
    "'329','330','364','369','370','371','372','373','374','375','378','379','380',\n",
    "'381','394','395','396','397','398','399','400','401','402','403','404','414',\n",
    "'422','449','450','451','458','461','462','463','464','465','466','481','498',\n",
    "'501','502','503','504','505','506','507','508','509','512','513','514','515',\n",
    "'528','529','530','531','532','533','534','535','536','537','538' ]\n",
    "    \n",
    "    df = df.drop(single_value_columns, axis=1 )\n",
    "    \n",
    "    # split the df into X and y in here \n",
    "    y = df['Pass/Fail']\n",
    "    X = df.drop('Pass/Fail' , axis=1)\n",
    "    \n",
    "    # and continue use the train-test slpit in here that use 70% of the data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state= 1)\n",
    "    \n",
    "    # we scale the value in here \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "    \n",
    "    # 一开始return df 然后现在换 return X_train, X_test, y_train, y_test\n",
    "    # return X, y\n",
    "    return X_train, X_test, y_train, y_test \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             0         1         2         3         4         6         7  \\\n",
       " 390  -0.349832 -0.784979 -0.702110 -0.837070 -0.062886  0.550891  0.079727   \n",
       " 635   0.033698  0.353357  0.015921 -1.183386 -0.051551  0.845131 -0.117085   \n",
       " 78    0.246294  0.059202 -0.586681  0.429161 -0.052493 -0.356155  0.263419   \n",
       " 733   0.315914 -1.701055  0.354622  0.405983 -0.058342  0.791001  0.027244   \n",
       " 1262 -0.448795  0.573974 -0.926520 -0.573652 -0.059723  0.447072  0.355265   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 715   0.760898 -0.466310  0.543717 -1.204002 -0.054619  0.995094 -0.340139   \n",
       " 905  -0.920769  0.379892  0.543337 -0.652297 -0.061495 -0.202822 -0.195810   \n",
       " 1096  0.659998 -0.060836  2.263423  1.479871 -0.047401 -1.023442 -0.051481   \n",
       " 235   0.423734 -0.074230 -0.101032 -0.341214 -0.062369 -0.213299 -0.222052   \n",
       " 1061  1.873705  1.582037  1.059743  1.401125 -0.053581 -1.198609  0.184694   \n",
       " \n",
       "              8         9        10  ...       576       577       582  \\\n",
       " 390   1.660382  0.575205 -2.431983  ... -0.229337 -0.101179 -1.421245   \n",
       " 635  -1.250633  0.022325  0.591865  ... -0.236675  0.059216 -0.063064   \n",
       " 78   -0.036013 -0.166304 -0.468738  ... -0.208856  0.044560 -1.155514   \n",
       " 733   0.827113  3.098939 -0.107682  ... -0.214130 -0.328386 -1.037412   \n",
       " 1262 -1.193634 -1.285073 -1.168285  ... -0.195474 -0.249656 -1.509822   \n",
       " ...        ...       ...       ...  ...       ...       ...       ...   \n",
       " 715  -0.701000 -1.239541  0.275941  ... -0.219221 -0.656602 -1.096463   \n",
       " 905   0.057628  0.139406  0.501601  ... -0.213599 -0.647856  1.413220   \n",
       " 1096 -0.994138  0.399585 -0.615418  ... -0.216786 -0.198393  0.616026   \n",
       " 235  -0.521861 -2.176185 -0.175380  ... -0.267046 -0.597438 -1.568874   \n",
       " 1061 -0.596503  1.030518  1.065752  ... -0.220809 -0.347796  0.793180   \n",
       " \n",
       "            583       584       585       586       587       588       589  \n",
       " 390  -0.104493  0.090875 -0.091661 -0.896661 -0.895327 -0.972313 -0.222332  \n",
       " 635  -0.367069 -0.378555 -0.351676  0.896361  0.747328  0.485680 -0.307801  \n",
       " 78   -0.185286 -0.065602 -0.176462 -0.488429  0.120526  0.054910  0.135286  \n",
       " 733   0.232143  0.122170  0.233756  0.952392 -0.884520 -0.773496 -0.787101  \n",
       " 1262 -0.037166 -0.159488 -0.028790 -0.632511  1.730761  1.811128  1.406800  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 715   0.009963 -0.034307  0.017244 -1.152807  0.477155  0.386272  1.968328  \n",
       " 905  -0.225682 -0.284669 -0.223534 -0.040173 -0.549505 -0.574678 -0.484059  \n",
       " 1096 -0.272811 -0.128193 -0.268303 -0.296319 -0.938555 -0.972313 -0.591078  \n",
       " 235  -0.205484 -0.003011 -0.191936 -2.001291 -0.787258 -0.773496  1.767280  \n",
       " 1061 -0.030433 -0.065602 -0.035927 -0.216273 -1.154694 -1.204266 -0.726385  \n",
       " \n",
       " [1096 rows x 442 columns],\n",
       "              0         1         2         3         4         6          7  \\\n",
       " 60    0.373492  2.504178  0.201981 -0.347823 -0.054060  0.065511   0.119090   \n",
       " 995  -0.452532  0.405415 -0.001828  0.001676 -0.003646 -0.022941  -0.022418   \n",
       " 1469 -1.618349  0.651050 -0.001828  0.001676 -0.003646 -0.022941 -16.006409   \n",
       " 895  -0.807273  0.282724 -0.450744  1.255124 -0.055484 -2.102812   0.329023   \n",
       " 321  -1.086582  0.380271 -0.133685  0.453400 -0.048491 -0.342323   0.079727   \n",
       " ...        ...       ...       ...       ...       ...       ...        ...   \n",
       " 1201  1.106228  0.064888 -0.413153 -1.045647 -0.060978  0.736520   0.158452   \n",
       " 718  -0.315092  0.216009  0.981901  0.362006 -0.049872  0.243330   0.197815   \n",
       " 148  -0.793986  1.084197  0.815970 -0.920102 -0.053813  0.091067  -0.379502   \n",
       " 336  -1.768384  0.695527  0.033384 -0.962403 -0.062690 -0.201400  -0.235173   \n",
       " 525  -0.284227  0.116567  1.159226  0.446829 -0.045110 -1.287335  -0.418864   \n",
       " \n",
       "              8         9        10  ...       576       577       582  \\\n",
       " 60    1.745881  1.115076 -0.468738  ... -0.226401 -0.548290  1.147488   \n",
       " 995   0.221839  0.854897  0.106695  ... -0.175151 -0.313558  0.379821   \n",
       " 1469 -0.293866  1.498840  0.422620  ... -0.231926 -0.280254  1.058911   \n",
       " 895  -0.717286  0.757330  0.704695  ... -0.199833  0.256267  0.084564   \n",
       " 321   0.396907 -0.426483 -1.698587  ...  5.195253  0.471687  0.114090   \n",
       " ...        ...       ...       ...  ...       ...       ...       ...   \n",
       " 1201  0.892254 -0.595599 -0.073833  ... -0.186005 -0.039916  0.232192   \n",
       " 718  -0.502861 -0.829760  2.227902  ... -0.210754 -0.194852 -2.425118   \n",
       " 148   1.350960 -0.836264 -0.536436  ... -0.193093 -0.260623  0.763655   \n",
       " 336  -1.004995 -0.010197  0.682129  ... -0.228611 -0.261058  2.387567   \n",
       " 525   1.511099 -0.003692 -0.299493  ... -0.220137 -0.249975  1.354168   \n",
       " \n",
       "            583       584       585       586       587       588       589  \n",
       " 60   -0.239148 -0.253374 -0.235862 -0.120219  0.541996  0.717634  0.067296  \n",
       " 995   0.380262  0.090875  0.360795 -0.128223  0.423120  0.253727  0.012437  \n",
       " 1469  0.063825  0.059579  0.050820 -0.392374  1.557849  1.015860  0.868385  \n",
       " 895   0.158083  0.059579  0.153367  0.976406 -1.046625 -0.939177 -0.837118  \n",
       " 321   0.151350  0.216056  0.141591 -0.360356 -0.754837 -0.939177 -0.467425  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 1201 -0.326673 -0.378555 -0.319430  1.016429 -0.279331 -0.508406 -0.626926  \n",
       " 718  -0.104493 -0.128193 -0.083810 -0.760584 -0.484663 -0.442134 -0.010452  \n",
       " 148  -0.420931 -0.378555 -0.411011 -1.288885  0.563610  0.353135  3.060523  \n",
       " 336   0.117686  0.309942  0.094810  1.096475  0.261016  0.220591 -0.491603  \n",
       " 525   0.070557  0.153465  0.056141  0.007854  1.255255  0.916451  0.297628  \n",
       " \n",
       " [471 rows x 442 columns],\n",
       " 390     Pass\n",
       " 635     Pass\n",
       " 78      Pass\n",
       " 733     Pass\n",
       " 1262    Pass\n",
       "         ... \n",
       " 715     Pass\n",
       " 905     Pass\n",
       " 1096    Pass\n",
       " 235     Fail\n",
       " 1061    Pass\n",
       " Name: Pass/Fail, Length: 1096, dtype: object,\n",
       " 60      Pass\n",
       " 995     Pass\n",
       " 1469    Pass\n",
       " 895     Pass\n",
       " 321     Fail\n",
       "         ... \n",
       " 1201    Pass\n",
       " 718     Pass\n",
       " 148     Pass\n",
       " 336     Fail\n",
       " 525     Pass\n",
       " Name: Pass/Fail, Length: 471, dtype: object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most important check the objective have missing value or not ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8232b15a423e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pass/Fail'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "x['Pass/Fail'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-51f346e71c62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# let see the missing value in each columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "# let see the missing value in each columns \n",
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-530e0f67f7c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# this guy check the missing value if the mean is greater than 25% he will remove the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "# this guy check the missing value if the mean is greater than 25% he will remove the columns\n",
    "x.isna().mean() >= 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thus he highlight the cloums that are true isna\n",
    "x.columns[x.isna().mean()>= 0.25] \n",
    "\n",
    "# we go back to drop these columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we droped the mean that are greater than 0.25 thus we continue to fil in the mean of na in the remain columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all the na had been fill, we make the objective value to be more clear using replace function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then split df into X and y and use train test slpit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_input(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-0.349832</td>\n",
       "      <td>-0.784979</td>\n",
       "      <td>-0.702110</td>\n",
       "      <td>-0.837070</td>\n",
       "      <td>-0.062886</td>\n",
       "      <td>0.550891</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>1.660382</td>\n",
       "      <td>0.575205</td>\n",
       "      <td>-2.431983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229337</td>\n",
       "      <td>-0.101179</td>\n",
       "      <td>-1.421245</td>\n",
       "      <td>-0.104493</td>\n",
       "      <td>0.090875</td>\n",
       "      <td>-0.091661</td>\n",
       "      <td>-0.896661</td>\n",
       "      <td>-0.895327</td>\n",
       "      <td>-0.972313</td>\n",
       "      <td>-0.222332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.033698</td>\n",
       "      <td>0.353357</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>-1.183386</td>\n",
       "      <td>-0.051551</td>\n",
       "      <td>0.845131</td>\n",
       "      <td>-0.117085</td>\n",
       "      <td>-1.250633</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.591865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236675</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>-0.063064</td>\n",
       "      <td>-0.367069</td>\n",
       "      <td>-0.378555</td>\n",
       "      <td>-0.351676</td>\n",
       "      <td>0.896361</td>\n",
       "      <td>0.747328</td>\n",
       "      <td>0.485680</td>\n",
       "      <td>-0.307801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.246294</td>\n",
       "      <td>0.059202</td>\n",
       "      <td>-0.586681</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>-0.052493</td>\n",
       "      <td>-0.356155</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>-0.036013</td>\n",
       "      <td>-0.166304</td>\n",
       "      <td>-0.468738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208856</td>\n",
       "      <td>0.044560</td>\n",
       "      <td>-1.155514</td>\n",
       "      <td>-0.185286</td>\n",
       "      <td>-0.065602</td>\n",
       "      <td>-0.176462</td>\n",
       "      <td>-0.488429</td>\n",
       "      <td>0.120526</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.315914</td>\n",
       "      <td>-1.701055</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>0.405983</td>\n",
       "      <td>-0.058342</td>\n",
       "      <td>0.791001</td>\n",
       "      <td>0.027244</td>\n",
       "      <td>0.827113</td>\n",
       "      <td>3.098939</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214130</td>\n",
       "      <td>-0.328386</td>\n",
       "      <td>-1.037412</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.122170</td>\n",
       "      <td>0.233756</td>\n",
       "      <td>0.952392</td>\n",
       "      <td>-0.884520</td>\n",
       "      <td>-0.773496</td>\n",
       "      <td>-0.787101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>-0.448795</td>\n",
       "      <td>0.573974</td>\n",
       "      <td>-0.926520</td>\n",
       "      <td>-0.573652</td>\n",
       "      <td>-0.059723</td>\n",
       "      <td>0.447072</td>\n",
       "      <td>0.355265</td>\n",
       "      <td>-1.193634</td>\n",
       "      <td>-1.285073</td>\n",
       "      <td>-1.168285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195474</td>\n",
       "      <td>-0.249656</td>\n",
       "      <td>-1.509822</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>-0.159488</td>\n",
       "      <td>-0.028790</td>\n",
       "      <td>-0.632511</td>\n",
       "      <td>1.730761</td>\n",
       "      <td>1.811128</td>\n",
       "      <td>1.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.760898</td>\n",
       "      <td>-0.466310</td>\n",
       "      <td>0.543717</td>\n",
       "      <td>-1.204002</td>\n",
       "      <td>-0.054619</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>-0.340139</td>\n",
       "      <td>-0.701000</td>\n",
       "      <td>-1.239541</td>\n",
       "      <td>0.275941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219221</td>\n",
       "      <td>-0.656602</td>\n",
       "      <td>-1.096463</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>-1.152807</td>\n",
       "      <td>0.477155</td>\n",
       "      <td>0.386272</td>\n",
       "      <td>1.968328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>-0.920769</td>\n",
       "      <td>0.379892</td>\n",
       "      <td>0.543337</td>\n",
       "      <td>-0.652297</td>\n",
       "      <td>-0.061495</td>\n",
       "      <td>-0.202822</td>\n",
       "      <td>-0.195810</td>\n",
       "      <td>0.057628</td>\n",
       "      <td>0.139406</td>\n",
       "      <td>0.501601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213599</td>\n",
       "      <td>-0.647856</td>\n",
       "      <td>1.413220</td>\n",
       "      <td>-0.225682</td>\n",
       "      <td>-0.284669</td>\n",
       "      <td>-0.223534</td>\n",
       "      <td>-0.040173</td>\n",
       "      <td>-0.549505</td>\n",
       "      <td>-0.574678</td>\n",
       "      <td>-0.484059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.659998</td>\n",
       "      <td>-0.060836</td>\n",
       "      <td>2.263423</td>\n",
       "      <td>1.479871</td>\n",
       "      <td>-0.047401</td>\n",
       "      <td>-1.023442</td>\n",
       "      <td>-0.051481</td>\n",
       "      <td>-0.994138</td>\n",
       "      <td>0.399585</td>\n",
       "      <td>-0.615418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216786</td>\n",
       "      <td>-0.198393</td>\n",
       "      <td>0.616026</td>\n",
       "      <td>-0.272811</td>\n",
       "      <td>-0.128193</td>\n",
       "      <td>-0.268303</td>\n",
       "      <td>-0.296319</td>\n",
       "      <td>-0.938555</td>\n",
       "      <td>-0.972313</td>\n",
       "      <td>-0.591078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.423734</td>\n",
       "      <td>-0.074230</td>\n",
       "      <td>-0.101032</td>\n",
       "      <td>-0.341214</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>-0.213299</td>\n",
       "      <td>-0.222052</td>\n",
       "      <td>-0.521861</td>\n",
       "      <td>-2.176185</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267046</td>\n",
       "      <td>-0.597438</td>\n",
       "      <td>-1.568874</td>\n",
       "      <td>-0.205484</td>\n",
       "      <td>-0.003011</td>\n",
       "      <td>-0.191936</td>\n",
       "      <td>-2.001291</td>\n",
       "      <td>-0.787258</td>\n",
       "      <td>-0.773496</td>\n",
       "      <td>1.767280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1.873705</td>\n",
       "      <td>1.582037</td>\n",
       "      <td>1.059743</td>\n",
       "      <td>1.401125</td>\n",
       "      <td>-0.053581</td>\n",
       "      <td>-1.198609</td>\n",
       "      <td>0.184694</td>\n",
       "      <td>-0.596503</td>\n",
       "      <td>1.030518</td>\n",
       "      <td>1.065752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220809</td>\n",
       "      <td>-0.347796</td>\n",
       "      <td>0.793180</td>\n",
       "      <td>-0.030433</td>\n",
       "      <td>-0.065602</td>\n",
       "      <td>-0.035927</td>\n",
       "      <td>-0.216273</td>\n",
       "      <td>-1.154694</td>\n",
       "      <td>-1.204266</td>\n",
       "      <td>-0.726385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         6         7  \\\n",
       "390  -0.349832 -0.784979 -0.702110 -0.837070 -0.062886  0.550891  0.079727   \n",
       "635   0.033698  0.353357  0.015921 -1.183386 -0.051551  0.845131 -0.117085   \n",
       "78    0.246294  0.059202 -0.586681  0.429161 -0.052493 -0.356155  0.263419   \n",
       "733   0.315914 -1.701055  0.354622  0.405983 -0.058342  0.791001  0.027244   \n",
       "1262 -0.448795  0.573974 -0.926520 -0.573652 -0.059723  0.447072  0.355265   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "715   0.760898 -0.466310  0.543717 -1.204002 -0.054619  0.995094 -0.340139   \n",
       "905  -0.920769  0.379892  0.543337 -0.652297 -0.061495 -0.202822 -0.195810   \n",
       "1096  0.659998 -0.060836  2.263423  1.479871 -0.047401 -1.023442 -0.051481   \n",
       "235   0.423734 -0.074230 -0.101032 -0.341214 -0.062369 -0.213299 -0.222052   \n",
       "1061  1.873705  1.582037  1.059743  1.401125 -0.053581 -1.198609  0.184694   \n",
       "\n",
       "             8         9        10  ...       576       577       582  \\\n",
       "390   1.660382  0.575205 -2.431983  ... -0.229337 -0.101179 -1.421245   \n",
       "635  -1.250633  0.022325  0.591865  ... -0.236675  0.059216 -0.063064   \n",
       "78   -0.036013 -0.166304 -0.468738  ... -0.208856  0.044560 -1.155514   \n",
       "733   0.827113  3.098939 -0.107682  ... -0.214130 -0.328386 -1.037412   \n",
       "1262 -1.193634 -1.285073 -1.168285  ... -0.195474 -0.249656 -1.509822   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "715  -0.701000 -1.239541  0.275941  ... -0.219221 -0.656602 -1.096463   \n",
       "905   0.057628  0.139406  0.501601  ... -0.213599 -0.647856  1.413220   \n",
       "1096 -0.994138  0.399585 -0.615418  ... -0.216786 -0.198393  0.616026   \n",
       "235  -0.521861 -2.176185 -0.175380  ... -0.267046 -0.597438 -1.568874   \n",
       "1061 -0.596503  1.030518  1.065752  ... -0.220809 -0.347796  0.793180   \n",
       "\n",
       "           583       584       585       586       587       588       589  \n",
       "390  -0.104493  0.090875 -0.091661 -0.896661 -0.895327 -0.972313 -0.222332  \n",
       "635  -0.367069 -0.378555 -0.351676  0.896361  0.747328  0.485680 -0.307801  \n",
       "78   -0.185286 -0.065602 -0.176462 -0.488429  0.120526  0.054910  0.135286  \n",
       "733   0.232143  0.122170  0.233756  0.952392 -0.884520 -0.773496 -0.787101  \n",
       "1262 -0.037166 -0.159488 -0.028790 -0.632511  1.730761  1.811128  1.406800  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "715   0.009963 -0.034307  0.017244 -1.152807  0.477155  0.386272  1.968328  \n",
       "905  -0.225682 -0.284669 -0.223534 -0.040173 -0.549505 -0.574678 -0.484059  \n",
       "1096 -0.272811 -0.128193 -0.268303 -0.296319 -0.938555 -0.972313 -0.591078  \n",
       "235  -0.205484 -0.003011 -0.191936 -2.001291 -0.787258 -0.773496  1.767280  \n",
       "1061 -0.030433 -0.065602 -0.035927 -0.216273 -1.154694 -1.204266 -0.726385  \n",
       "\n",
       "[1096 rows x 442 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390     Pass\n",
       "635     Pass\n",
       "78      Pass\n",
       "733     Pass\n",
       "1262    Pass\n",
       "        ... \n",
       "715     Pass\n",
       "905     Pass\n",
       "1096    Pass\n",
       "235     Fail\n",
       "1061    Pass\n",
       "Name: Pass/Fail, Length: 1096, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to scale the value of the training sets as they are too big diffenrent in between the number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number like 3000 and 3 in the test set have too big gap that will make the ML model to know perfrom well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_input(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-0.349832</td>\n",
       "      <td>-0.784979</td>\n",
       "      <td>-0.702110</td>\n",
       "      <td>-0.837070</td>\n",
       "      <td>-0.062886</td>\n",
       "      <td>0.550891</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>1.660382</td>\n",
       "      <td>0.575205</td>\n",
       "      <td>-2.431983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229337</td>\n",
       "      <td>-0.101179</td>\n",
       "      <td>-1.421245</td>\n",
       "      <td>-0.104493</td>\n",
       "      <td>0.090875</td>\n",
       "      <td>-0.091661</td>\n",
       "      <td>-0.896661</td>\n",
       "      <td>-0.895327</td>\n",
       "      <td>-0.972313</td>\n",
       "      <td>-0.222332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.033698</td>\n",
       "      <td>0.353357</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>-1.183386</td>\n",
       "      <td>-0.051551</td>\n",
       "      <td>0.845131</td>\n",
       "      <td>-0.117085</td>\n",
       "      <td>-1.250633</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.591865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236675</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>-0.063064</td>\n",
       "      <td>-0.367069</td>\n",
       "      <td>-0.378555</td>\n",
       "      <td>-0.351676</td>\n",
       "      <td>0.896361</td>\n",
       "      <td>0.747328</td>\n",
       "      <td>0.485680</td>\n",
       "      <td>-0.307801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.246294</td>\n",
       "      <td>0.059202</td>\n",
       "      <td>-0.586681</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>-0.052493</td>\n",
       "      <td>-0.356155</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>-0.036013</td>\n",
       "      <td>-0.166304</td>\n",
       "      <td>-0.468738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208856</td>\n",
       "      <td>0.044560</td>\n",
       "      <td>-1.155514</td>\n",
       "      <td>-0.185286</td>\n",
       "      <td>-0.065602</td>\n",
       "      <td>-0.176462</td>\n",
       "      <td>-0.488429</td>\n",
       "      <td>0.120526</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.315914</td>\n",
       "      <td>-1.701055</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>0.405983</td>\n",
       "      <td>-0.058342</td>\n",
       "      <td>0.791001</td>\n",
       "      <td>0.027244</td>\n",
       "      <td>0.827113</td>\n",
       "      <td>3.098939</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214130</td>\n",
       "      <td>-0.328386</td>\n",
       "      <td>-1.037412</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.122170</td>\n",
       "      <td>0.233756</td>\n",
       "      <td>0.952392</td>\n",
       "      <td>-0.884520</td>\n",
       "      <td>-0.773496</td>\n",
       "      <td>-0.787101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>-0.448795</td>\n",
       "      <td>0.573974</td>\n",
       "      <td>-0.926520</td>\n",
       "      <td>-0.573652</td>\n",
       "      <td>-0.059723</td>\n",
       "      <td>0.447072</td>\n",
       "      <td>0.355265</td>\n",
       "      <td>-1.193634</td>\n",
       "      <td>-1.285073</td>\n",
       "      <td>-1.168285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195474</td>\n",
       "      <td>-0.249656</td>\n",
       "      <td>-1.509822</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>-0.159488</td>\n",
       "      <td>-0.028790</td>\n",
       "      <td>-0.632511</td>\n",
       "      <td>1.730761</td>\n",
       "      <td>1.811128</td>\n",
       "      <td>1.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.760898</td>\n",
       "      <td>-0.466310</td>\n",
       "      <td>0.543717</td>\n",
       "      <td>-1.204002</td>\n",
       "      <td>-0.054619</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>-0.340139</td>\n",
       "      <td>-0.701000</td>\n",
       "      <td>-1.239541</td>\n",
       "      <td>0.275941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219221</td>\n",
       "      <td>-0.656602</td>\n",
       "      <td>-1.096463</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>-1.152807</td>\n",
       "      <td>0.477155</td>\n",
       "      <td>0.386272</td>\n",
       "      <td>1.968328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>-0.920769</td>\n",
       "      <td>0.379892</td>\n",
       "      <td>0.543337</td>\n",
       "      <td>-0.652297</td>\n",
       "      <td>-0.061495</td>\n",
       "      <td>-0.202822</td>\n",
       "      <td>-0.195810</td>\n",
       "      <td>0.057628</td>\n",
       "      <td>0.139406</td>\n",
       "      <td>0.501601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213599</td>\n",
       "      <td>-0.647856</td>\n",
       "      <td>1.413220</td>\n",
       "      <td>-0.225682</td>\n",
       "      <td>-0.284669</td>\n",
       "      <td>-0.223534</td>\n",
       "      <td>-0.040173</td>\n",
       "      <td>-0.549505</td>\n",
       "      <td>-0.574678</td>\n",
       "      <td>-0.484059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.659998</td>\n",
       "      <td>-0.060836</td>\n",
       "      <td>2.263423</td>\n",
       "      <td>1.479871</td>\n",
       "      <td>-0.047401</td>\n",
       "      <td>-1.023442</td>\n",
       "      <td>-0.051481</td>\n",
       "      <td>-0.994138</td>\n",
       "      <td>0.399585</td>\n",
       "      <td>-0.615418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216786</td>\n",
       "      <td>-0.198393</td>\n",
       "      <td>0.616026</td>\n",
       "      <td>-0.272811</td>\n",
       "      <td>-0.128193</td>\n",
       "      <td>-0.268303</td>\n",
       "      <td>-0.296319</td>\n",
       "      <td>-0.938555</td>\n",
       "      <td>-0.972313</td>\n",
       "      <td>-0.591078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.423734</td>\n",
       "      <td>-0.074230</td>\n",
       "      <td>-0.101032</td>\n",
       "      <td>-0.341214</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>-0.213299</td>\n",
       "      <td>-0.222052</td>\n",
       "      <td>-0.521861</td>\n",
       "      <td>-2.176185</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267046</td>\n",
       "      <td>-0.597438</td>\n",
       "      <td>-1.568874</td>\n",
       "      <td>-0.205484</td>\n",
       "      <td>-0.003011</td>\n",
       "      <td>-0.191936</td>\n",
       "      <td>-2.001291</td>\n",
       "      <td>-0.787258</td>\n",
       "      <td>-0.773496</td>\n",
       "      <td>1.767280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1.873705</td>\n",
       "      <td>1.582037</td>\n",
       "      <td>1.059743</td>\n",
       "      <td>1.401125</td>\n",
       "      <td>-0.053581</td>\n",
       "      <td>-1.198609</td>\n",
       "      <td>0.184694</td>\n",
       "      <td>-0.596503</td>\n",
       "      <td>1.030518</td>\n",
       "      <td>1.065752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220809</td>\n",
       "      <td>-0.347796</td>\n",
       "      <td>0.793180</td>\n",
       "      <td>-0.030433</td>\n",
       "      <td>-0.065602</td>\n",
       "      <td>-0.035927</td>\n",
       "      <td>-0.216273</td>\n",
       "      <td>-1.154694</td>\n",
       "      <td>-1.204266</td>\n",
       "      <td>-0.726385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         6         7  \\\n",
       "390  -0.349832 -0.784979 -0.702110 -0.837070 -0.062886  0.550891  0.079727   \n",
       "635   0.033698  0.353357  0.015921 -1.183386 -0.051551  0.845131 -0.117085   \n",
       "78    0.246294  0.059202 -0.586681  0.429161 -0.052493 -0.356155  0.263419   \n",
       "733   0.315914 -1.701055  0.354622  0.405983 -0.058342  0.791001  0.027244   \n",
       "1262 -0.448795  0.573974 -0.926520 -0.573652 -0.059723  0.447072  0.355265   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "715   0.760898 -0.466310  0.543717 -1.204002 -0.054619  0.995094 -0.340139   \n",
       "905  -0.920769  0.379892  0.543337 -0.652297 -0.061495 -0.202822 -0.195810   \n",
       "1096  0.659998 -0.060836  2.263423  1.479871 -0.047401 -1.023442 -0.051481   \n",
       "235   0.423734 -0.074230 -0.101032 -0.341214 -0.062369 -0.213299 -0.222052   \n",
       "1061  1.873705  1.582037  1.059743  1.401125 -0.053581 -1.198609  0.184694   \n",
       "\n",
       "             8         9        10  ...       576       577       582  \\\n",
       "390   1.660382  0.575205 -2.431983  ... -0.229337 -0.101179 -1.421245   \n",
       "635  -1.250633  0.022325  0.591865  ... -0.236675  0.059216 -0.063064   \n",
       "78   -0.036013 -0.166304 -0.468738  ... -0.208856  0.044560 -1.155514   \n",
       "733   0.827113  3.098939 -0.107682  ... -0.214130 -0.328386 -1.037412   \n",
       "1262 -1.193634 -1.285073 -1.168285  ... -0.195474 -0.249656 -1.509822   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "715  -0.701000 -1.239541  0.275941  ... -0.219221 -0.656602 -1.096463   \n",
       "905   0.057628  0.139406  0.501601  ... -0.213599 -0.647856  1.413220   \n",
       "1096 -0.994138  0.399585 -0.615418  ... -0.216786 -0.198393  0.616026   \n",
       "235  -0.521861 -2.176185 -0.175380  ... -0.267046 -0.597438 -1.568874   \n",
       "1061 -0.596503  1.030518  1.065752  ... -0.220809 -0.347796  0.793180   \n",
       "\n",
       "           583       584       585       586       587       588       589  \n",
       "390  -0.104493  0.090875 -0.091661 -0.896661 -0.895327 -0.972313 -0.222332  \n",
       "635  -0.367069 -0.378555 -0.351676  0.896361  0.747328  0.485680 -0.307801  \n",
       "78   -0.185286 -0.065602 -0.176462 -0.488429  0.120526  0.054910  0.135286  \n",
       "733   0.232143  0.122170  0.233756  0.952392 -0.884520 -0.773496 -0.787101  \n",
       "1262 -0.037166 -0.159488 -0.028790 -0.632511  1.730761  1.811128  1.406800  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "715   0.009963 -0.034307  0.017244 -1.152807  0.477155  0.386272  1.968328  \n",
       "905  -0.225682 -0.284669 -0.223534 -0.040173 -0.549505 -0.574678 -0.484059  \n",
       "1096 -0.272811 -0.128193 -0.268303 -0.296319 -0.938555 -0.972313 -0.591078  \n",
       "235  -0.205484 -0.003011 -0.191936 -2.001291 -0.787258 -0.773496  1.767280  \n",
       "1061 -0.030433 -0.065602 -0.035927 -0.216273 -1.154694 -1.204266 -0.726385  \n",
       "\n",
       "[1096 rows x 442 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data had been scale to same scale in between -1 and 1 \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1cfa23de7b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# we return x and y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# the 5 become 0 bcs it have single value and we want to remove it \n",
    "# the reason of have single value bcs me fit the Na wor \n",
    "# thus we need to find it before the test \n",
    "\n",
    "# we return x and y \n",
    "X, y = preprocess_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to memorize it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-24700333edbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# then use pandas series to count the single value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# then use pandas series to count the single value \n",
    "(pd.Series({column: len(X[column].unique()) for column in X.columns}) ==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1521\n",
       "1      1505\n",
       "2       508\n",
       "3       519\n",
       "4       504\n",
       "       ... \n",
       "585    1503\n",
       "586     323\n",
       "587     261\n",
       "588     121\n",
       "589     612\n",
       "Length: 558, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 116 colunms that have single value \n",
    "#@1 so to know which are the 116 -right now we only know no5 is one of the 116 single value- \n",
    "pd.Series({column: len(X[column].unique()) for column in X.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "585    False\n",
       "586    False\n",
       "587    False\n",
       "588    False\n",
       "589    False\n",
       "Length: 558, dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@2 and we take the true false of the 116\n",
    "pd.Series({column: len(X[column].unique()) for column in X.columns}) ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['5', '13', '42', '49', '52', '69', '97', '141', '149', '178',\n",
       "       ...\n",
       "       '529', '530', '531', '532', '533', '534', '535', '536', '537', '538'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### we mix @1 and @2 tgt to show the result of it \n",
    "pd.Series({column: len(X[column].unique()) for column in X.columns})[pd.Series({column: len(X[column].unique()) for column in X.columns}) ==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we remove it we should define it we need to define it \n",
    "single_value_columns = pd.Series({column: len(X[column].unique()) for column in X.columns})[pd.Series({column: len(X[column].unique()) for column in X.columns}) ==1].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '13',\n",
       " '42',\n",
       " '49',\n",
       " '52',\n",
       " '69',\n",
       " '97',\n",
       " '141',\n",
       " '149',\n",
       " '178',\n",
       " '179',\n",
       " '186',\n",
       " '189',\n",
       " '190',\n",
       " '191',\n",
       " '192',\n",
       " '193',\n",
       " '194',\n",
       " '226',\n",
       " '229',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '234',\n",
       " '235',\n",
       " '236',\n",
       " '237',\n",
       " '240',\n",
       " '241',\n",
       " '242',\n",
       " '243',\n",
       " '256',\n",
       " '257',\n",
       " '258',\n",
       " '259',\n",
       " '260',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '264',\n",
       " '265',\n",
       " '266',\n",
       " '276',\n",
       " '284',\n",
       " '313',\n",
       " '314',\n",
       " '315',\n",
       " '322',\n",
       " '325',\n",
       " '326',\n",
       " '327',\n",
       " '328',\n",
       " '329',\n",
       " '330',\n",
       " '364',\n",
       " '369',\n",
       " '370',\n",
       " '371',\n",
       " '372',\n",
       " '373',\n",
       " '374',\n",
       " '375',\n",
       " '378',\n",
       " '379',\n",
       " '380',\n",
       " '381',\n",
       " '394',\n",
       " '395',\n",
       " '396',\n",
       " '397',\n",
       " '398',\n",
       " '399',\n",
       " '400',\n",
       " '401',\n",
       " '402',\n",
       " '403',\n",
       " '404',\n",
       " '414',\n",
       " '422',\n",
       " '449',\n",
       " '450',\n",
       " '451',\n",
       " '458',\n",
       " '461',\n",
       " '462',\n",
       " '463',\n",
       " '464',\n",
       " '465',\n",
       " '466',\n",
       " '481',\n",
       " '498',\n",
       " '501',\n",
       " '502',\n",
       " '503',\n",
       " '504',\n",
       " '505',\n",
       " '506',\n",
       " '507',\n",
       " '508',\n",
       " '509',\n",
       " '512',\n",
       " '513',\n",
       " '514',\n",
       " '515',\n",
       " '528',\n",
       " '529',\n",
       " '530',\n",
       " '531',\n",
       " '532',\n",
       " '533',\n",
       " '534',\n",
       " '535',\n",
       " '536',\n",
       " '537',\n",
       " '538']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(single_value_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This number need to remove before apply it to the test_split function\n",
    "'5','13','42','49','52','69','97','141','149','178','179','186','189','190',\n",
    "'191','192','193','194','226','229','230','231','232','233','234','235','236',\n",
    "'237','240','241','242','243','256','257','258','259','260','261','262','263',\n",
    "'264','265','266','276','284','313','314','315','322','325','326','327','328',\n",
    "'329','330','364','369','370','371','372','373','374','375','378','379','380',\n",
    "'381','394','395','396','397','398','399','400','401','402','403','404','414',\n",
    "'422','449','450','451','458','461','462','463','464','465','466','481','498',\n",
    "'501','502','503','504','505','506','507','508','509','512','513','514','515',\n",
    "'528','529','530','531','532','533','534','535','536','537','538'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check again the single value still exsits or not  \n",
    "pd.Series({column: len(X_train[column].unique()) for column in X_train.columns})[pd.Series({column: len(X_train[column].unique()) for column in X_train.columns}) ==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examming Class Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-94040bf0b89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.train.value.counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a model (Imbalanced Class-\n",
    "# this can look back the video in supply chain \n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \n",
    "    acc = model.score(X_test, y_test)\n",
    "    print(\"Accuracy: {:.2f}%\".format(acc * 100))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred, labels=['PASS', 'FAIL'])\n",
    "    clr = classification_report(y_test, y_pred, labels=['PASS', 'FAIL'])\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "    plt.xticks(ticks=[0.5, 1.5], labels=[\"PASS\", \"FAIL\"])\n",
    "    plt.yticks(ticks=[0.5, 1.5], labels=[\"PASS\", \"FAIL\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.96%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-d95483d5e93b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-6020405703d9>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_test, y_test)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PASS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FAIL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mclr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PASS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FAIL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "# using logistic regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
